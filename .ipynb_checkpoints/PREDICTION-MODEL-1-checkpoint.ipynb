{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.classification import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.regression import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from dbn.tensorflow import SupervisedDBNRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "ROAD = \"Taft Ave.\"\n",
    "YEAR = \"2015\"\n",
    "EXT = \".csv\"\n",
    "WINDOWSIZE = 4\n",
    "TRANSFORMED = True\n",
    "DIR = \"../../../datasets/Thesis Datasets/mmda/\"\n",
    "\n",
    "if TRANSFORMED:\n",
    "    FILENAME = \"eng_win\" + str(WINDOWSIZE) + \"_mmda_\" + ROAD + \"_\" + YEAR + \"_transformed\"\n",
    "else:\n",
    "    FILENAME = \"eng_win\" + str(WINDOWSIZE) + \"_mmda_\" + ROAD + \"_\" + YEAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv(DIR + FILENAME + EXT, skipinitialspace=True)\n",
    "original_dataset = original_dataset.fillna(0)\n",
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing Traffic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_dataset = pd.read_csv(DIR + FILENAME + EXT, skipinitialspace=True)\n",
    "traffic_dataset = traffic_dataset.fillna(0)\n",
    "# Remove date time. Remove unused columms\n",
    "#0-2 = dt + lineName + stationName || 3-4 - statusN - statusS || 5-14 - original weather variables\n",
    "#15-46 - engineered traffic\n",
    "cols_to_remove = [0, 1, 2]\n",
    "\n",
    "# window 1\n",
    "statusN = list(range(5, 9))\n",
    "statusS = list(range(12, 16))\n",
    "\n",
    "cols_to_remove += statusN + statusS\n",
    "\n",
    "# window >= 2\n",
    "statusN2 = list(range(9, 12))\n",
    "statusS2 = list(range(16, 19))\n",
    "\n",
    "#cols_to_remove += statusN2 + statusS2\n",
    "\n",
    "#cols_to_remove += [3, 4] #statusN , statusS\n",
    "\n",
    "traffic_dataset.drop(traffic_dataset.columns[[cols_to_remove]], axis=1, inplace=True)\n",
    "traffic_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-be Predicted variable \n",
    "Y = traffic_dataset.statusS\n",
    "Y = Y.shift(-shift)\n",
    "Y = Y.fillna(0)\n",
    "Y = Y[:-shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other data\n",
    "X = traffic_dataset [:-shift]\n",
    "#X = dataset\n",
    "#X.statusS = X.statusS.round(5)\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.67, shuffle=False)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Data scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "regressor = SupervisedDBNRegression(hidden_layers_structure=[5, 10, 15],\n",
    "                                    learning_rate_rbm=0.01,\n",
    "                                    learning_rate=0.01,\n",
    "                                    n_epochs_rbm=2,\n",
    "                                    n_iter_backprop=5,\n",
    "                                    batch_size=28,\n",
    "                                    activation_function='relu')\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check RBM Loss Errors:\n",
    "#regressor.unsupervised_dbn.rbm_layers[i].rbm_loss_error\n",
    "\n",
    "#To check DBN Loss Errors\n",
    "#regressor.rbn_loss_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "Y_pred = regressor.predict(X_test)\n",
    "print('Done.\\nR-squared: %f\\nMSE: %f \\nMAE: %f' % (r2_score(Y_test, Y_pred), mean_squared_error(Y_test, Y_pred), mean_absolute_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_pred))\n",
    "temp = []\n",
    "for i in range(len(Y_pred)):\n",
    "    temp.append(Y_pred[i][0])\n",
    "d = {'Predicted': temp, 'Actual': Y_test}\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "regressor.save('models/pm1-witheng.pkl')\n",
    "\n",
    "# # Restore\n",
    "# classifier = SupervisedDBNClassification.load('model.pkl')\n",
    "\n",
    "# # Test\n",
    "# Y_pred = classifier.predict(X_test)\n",
    "# print('Done.\\nAccuracy: %f' % accuracy_score(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output/pm1_\" + FILENAME + EXT, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
